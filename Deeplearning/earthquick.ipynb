{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_io.TextIOWrapper' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7fdf73c0b9d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m# Load and prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"database.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0mdata_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mvectorsX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorsY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnitude\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7fdf73c0b9d2>\u001b[0m in \u001b[0;36mload_from_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0melements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{elements[0]} {elements[1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%m/%d/%Y %H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                     \u001b[0mlatitude\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mlongitude\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '_io.TextIOWrapper' object is not callable"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    @staticmethod\n",
    "    def load_from_file(filename):\n",
    "        '''\n",
    "        Load and return data from file\n",
    "        :param filename: path of the database.csv file\n",
    "        :return: (date, latitude, longitude, magnitude) (np.array)\n",
    "        '''\n",
    "        date, latitude, longitude, magnitude = [], [], [], []\n",
    "\n",
    "        with open(filename, \"r\") as f:\n",
    "            f.readline()  # Skip first line\n",
    "\n",
    "            for line in f:\n",
    "                elements = line.split(',')\n",
    "                try:\n",
    "                    date.append(datetime.strptime(f(\"{elements[0]} {elements[1]}\"),\"%m/%d/%Y %H:%M:%S\"))\n",
    "                    latitude.append(float(elements[2]))\n",
    "                    longitude.append(float(elements[3]))\n",
    "                    magnitude.append(elements[8])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        return np.array(date), np.float32(latitude), np.float32(longitude), np.float32(magnitude)\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_date(array):\n",
    "        '''\n",
    "        Normalize datetime array\n",
    "        :param array: array to normalize\n",
    "        :return: normalized array (np.array)\n",
    "        '''\n",
    "        min_data = min(array)\n",
    "        max_data = max(array)\n",
    "        delta = max_data - min_data\n",
    "\n",
    "        return np.float32([(d - min_data).total_seconds() / delta.total_seconds() for d in array])\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_cord(latitude, longitude):\n",
    "        '''\n",
    "        Normalize GPS cord array, assuming the earth is shpherical\n",
    "        :param latitude: latitude array to normalize\n",
    "        :param longitude: longitude array to normalize\n",
    "        :return: normalized arrays (np.array)\n",
    "        '''\n",
    "        rad_lat = np.deg2rad(latitude)\n",
    "        rad_lon = np.deg2rad(longitude)\n",
    "\n",
    "        x = np.cos(rad_lat) * np.cos(rad_lon)\n",
    "        y = np.cos(rad_lat) * np.sin(rad_lon)\n",
    "        z = np.sin(rad_lat)\n",
    "\n",
    "        return x, y, z\n",
    "\n",
    "    @staticmethod\n",
    "    def vectorize(date, latitude, longitude):\n",
    "        '''\n",
    "        Transform given array in a vectors to feed NN\n",
    "        :param date: date array\n",
    "        :param latitude: latitude array\n",
    "        :param longitude: longitude array\n",
    "        :return: np.array\n",
    "        '''\n",
    "        return np.concatenate(Dataset.normalize_cord(latitude, longitude) + (Dataset.normalize_date(date),))\\\n",
    "            .reshape((4, len(date)))\\\n",
    "            .swapaxes(0, 1)\n",
    "\n",
    "\n",
    "class Math:\n",
    "    @staticmethod\n",
    "    def sigmoid(x, deriv=False):\n",
    "        '''\n",
    "        SigmoÃ¯d function\n",
    "        :param x: np.array\n",
    "        :param deriv: derivate wanted ?\n",
    "        :return:\n",
    "        '''\n",
    "        if deriv:\n",
    "            return x * (1 - x)\n",
    "\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x, deriv=False):\n",
    "        '''\n",
    "        Rectifier function\n",
    "        :param x: np.array\n",
    "        :param deriv: derivate wanted ?\n",
    "        :return:\n",
    "        '''\n",
    "        if deriv:\n",
    "            return np.ones_like(x) * (x > 0)\n",
    "\n",
    "        return x * (x > 0)\n",
    "\n",
    "    @staticmethod\n",
    "    def new_parameters(x, x_min, x_max, radius):\n",
    "        '''\n",
    "        Generate new random parameters in the sphere of center and radius given\n",
    "        :param x: center on the sphere\n",
    "        :param x_min: minmium value returned\n",
    "        :param x_max: maximum value returned\n",
    "        :param radius: radius\n",
    "        :return: new parameter\n",
    "        '''\n",
    "        alpha = 2 * np.random.random() - 1\n",
    "        new_x = x + radius * alpha\n",
    "\n",
    "        if new_x < x_min:\n",
    "            return x_min\n",
    "        elif new_x > x_max:\n",
    "            return x_max\n",
    "\n",
    "        return new_x\n",
    "\n",
    "\n",
    "class Generator:\n",
    "    @staticmethod\n",
    "    def gen_random_batch(batch_size, X, Y):\n",
    "        '''\n",
    "        Generator for random batch\n",
    "        :param batch_size: size or the returned batches\n",
    "        :param X: X array\n",
    "        :param Y: Y array\n",
    "        :return: random batches of the given size\n",
    "        '''\n",
    "        while True:\n",
    "            index = np.arange(X.shape[0])\n",
    "            np.random.shuffle(index)\n",
    "\n",
    "            s_X, s_Y = X[index], Y[index]\n",
    "            for i in range(X.shape[0] // batch_size):\n",
    "                yield (X[i * batch_size:(i + 1) * batch_size], Y[i * batch_size:(i + 1) * batch_size])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_batch(batch_size, X, Y):\n",
    "        '''\n",
    "        Generator to split givens arrays in smaller batches\n",
    "        :param batch_size: size or the returned batches\n",
    "        :param X: X array\n",
    "        :param Y: Y array\n",
    "        :return: random batches of the given size\n",
    "        '''\n",
    "        if X.shape[0] % batch_size != 0:\n",
    "            print(\"[/!\\ Warning /!\\] the full set will not be executed because of a poor choice of batch_size\")\n",
    "\n",
    "        for i in range(X.shape[0] // batch_size):\n",
    "            yield X[i * batch_size:(i + 1) * batch_size], Y[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    date, latitude, longitude, magnitude = Dataset.load_from_file(\"database.csv\")\n",
    "    data_size = len(date)\n",
    "    vectorsX, vectorsY = Dataset.vectorize(date, latitude, longitude), magnitude.reshape((data_size, 1))\n",
    "\n",
    "    # Split vectors into train / eval sets\n",
    "    eval_set_size = int(0.1 * data_size)\n",
    "    index = np.arange(data_size)\n",
    "    np.random.shuffle(index)\n",
    "    trainX, trainY = vectorsX[index[eval_set_size:]], vectorsY[index[eval_set_size:]]\n",
    "    evalX, evalY = vectorsX[index[:eval_set_size]], vectorsY[index[:eval_set_size]]\n",
    "\n",
    "    # randomly initialize our weights with mean 0\n",
    "    syn0_origin = 2 * np.random.random((trainX.shape[1], 32)) - 1\n",
    "    syn1_origin = 2 * np.random.random((32, trainY.shape[1])) - 1\n",
    "\n",
    "    # Placeholder for hyperparameters\n",
    "    best_error = 9999\n",
    "    best_learning_rate_log = -3\n",
    "    best_momentum = 0.9\n",
    "    best_batch_size = 64\n",
    "    best_max_epochs_log = 4\n",
    "    learning_rate_log = None\n",
    "    momentum = None\n",
    "    batch_size = None\n",
    "    max_epochs_log = None\n",
    "\n",
    "    for i in range(50):\n",
    "        # Hyperparameters\n",
    "        learning_rate_log = Math.new_parameters(best_learning_rate_log, -5, -1, 0.5)  # log range from 0.0001 to 0.1\n",
    "        momentum = Math.new_parameters(best_momentum, 0.5, 0.95, 0.1)  # linear range from 0.5 to 0.9\n",
    "        batch_size = np.int64(Math.new_parameters(best_batch_size, 10, 128, 10))  # linear range from 10 to 128\n",
    "        max_epochs_log = Math.new_parameters(best_max_epochs_log, 3, 5, 0.5)  # log range from 1000 to 100000\n",
    "\n",
    "        learning_rate = np.power(10, learning_rate_log)\n",
    "        max_epochs = np.int64(np.power(10, max_epochs_log))\n",
    "\n",
    "        # Display hyperparameters\n",
    "        print(f(\"iteration: {i}\"))\n",
    "        print(f(\"learning rate: {learning_rate}\"))\n",
    "        print(f(\"momentum: {momentum}\"))\n",
    "        print(f(\"batch size: {batch_size}\"))\n",
    "        print(f(\"max epochs: {max_epochs}\"))\n",
    "\n",
    "        # reset weight\n",
    "        syn0 = copy.deepcopy(syn0_origin)\n",
    "        syn1 = copy.deepcopy(syn1_origin)\n",
    "\n",
    "        # initialize momentum\n",
    "        momentum_syn0 = np.zeros_like(syn0)\n",
    "        momentum_syn1 = np.zeros_like(syn1)\n",
    "\n",
    "        # get batch generator\n",
    "        batch_gen = Generator.gen_random_batch(batch_size, trainX, trainY)\n",
    "\n",
    "        # Train model\n",
    "        for j in range(max_epochs):\n",
    "            # Get Batch\n",
    "            batch = next(batch_gen)\n",
    "\n",
    "            # feed forward\n",
    "            l0 = batch[0]\n",
    "            l1 = Math.sigmoid(np.dot(l0, syn0))\n",
    "            l2 = Math.relu(np.dot(l1, syn1))\n",
    "\n",
    "            # l2 error & delta\n",
    "            l2_error = batch[1] - l2\n",
    "            l2_delta = l2_error * Math.relu(l2, deriv=True)\n",
    "\n",
    "            # l1 error & delta\n",
    "            l1_error = l2_delta.dot(syn1.T)\n",
    "            l1_delta = l1_error * Math.sigmoid(l1, deriv=True)\n",
    "\n",
    "            # momentum\n",
    "            momentum_syn1 = momentum * momentum_syn1 + l1.T.dot(l2_delta) * learning_rate\n",
    "            momentum_syn0 = momentum * momentum_syn0 + l0.T.dot(l1_delta) * learning_rate\n",
    "\n",
    "            # Apply momentum correction\n",
    "            syn1 += momentum_syn1\n",
    "            syn0 += momentum_syn0\n",
    "\n",
    "        # Evaluate model\n",
    "        current_error = 0\n",
    "        for batch in Generator.get_batch(10, evalX, evalY):\n",
    "            # feed forward\n",
    "            l0 = batch[0]\n",
    "            l1 = Math.sigmoid(np.dot(l0, syn0))\n",
    "            l2 = Math.relu(np.dot(l1, syn1))\n",
    "\n",
    "            # accumulate error\n",
    "            current_error += np.sum(np.abs(batch[1] - l2))\n",
    "        current_error /= eval_set_size\n",
    "\n",
    "        print(f(\"error: {current_error}\\n\"))\n",
    "\n",
    "        if current_error < best_error:\n",
    "            best_error = current_error\n",
    "            best_learning_rate_log = learning_rate_log\n",
    "            best_momentum = momentum\n",
    "            best_batch_size = batch_size\n",
    "            best_max_epochs_log = max_epochs_log\n",
    "\n",
    "    print(f(\"best error: {best_error}\"))\n",
    "    print(f(\"best learning rate log: {best_learning_rate_log}\"))\n",
    "    print(f(\"best momentum: {best_momentum}\"))\n",
    "    print(f(\"best batch size: {best_batch_size}\"))\n",
    "    print(f(\"best max epochs log: {best_max_epochs_log}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3.5]",
   "language": "python",
   "name": "conda-env-python3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
