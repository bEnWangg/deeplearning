{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random starting synaptic weights: \n",
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n",
      "New synaptic weights after training: \n",
      "[[ 9.67299303]\n",
      " [-0.2078435 ]\n",
      " [-4.62963669]]\n",
      "Considering new situation [1, 0, 0] -> ?: \n",
      "[ 0.99993704]\n"
     ]
    }
   ],
   "source": [
    "from numpy import exp, array, random, dot\n",
    "\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        # Seed the random number generator, so it generates the same numbers\n",
    "        # every time the program runs.\n",
    "        random.seed(1)\n",
    "\n",
    "        # We model a single neuron, with 3 input connections and 1 output connection.\n",
    "        # We assign random weights to a 3 x 1 matrix, with values in the range -1 to 1\n",
    "        # and mean 0.\n",
    "        self.synaptic_weights = 2 * random.random((3, 1)) - 1\n",
    "\n",
    "    # The Sigmoid function, which describes an S shaped curve.\n",
    "    # We pass the weighted sum of the inputs through this function to\n",
    "    # normalise them between 0 and 1.\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + exp(-x))\n",
    "\n",
    "    # The derivative of the Sigmoid function.\n",
    "    # This is the gradient of the Sigmoid curve.\n",
    "    # It indicates how confident we are about the existing weight.\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # We train the neural network through a process of trial and error.\n",
    "    # Adjusting the synaptic weights each time.\n",
    "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
    "        for iteration in range(number_of_training_iterations):\n",
    "            # Pass the training set through our neural network (a single neuron).\n",
    "            output = self.think(training_set_inputs)\n",
    "\n",
    "            # Calculate the error (The difference between the desired output\n",
    "            # and the predicted output).\n",
    "            error = training_set_outputs - output\n",
    "\n",
    "            # Multiply the error by the input and again by the gradient of the Sigmoid curve.\n",
    "            # This means less confident weights are adjusted more.\n",
    "            # This means inputs, which are zero, do not cause changes to the weights.\n",
    "            adjustment = dot(training_set_inputs.T, error * self.__sigmoid_derivative(output))\n",
    "\n",
    "            # Adjust the weights.\n",
    "            self.synaptic_weights += adjustment\n",
    "\n",
    "    # The neural network thinks.\n",
    "    def think(self, inputs):\n",
    "        # Pass inputs through our neural network (our single neuron).\n",
    "        return self.__sigmoid(dot(inputs, self.synaptic_weights))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #Intialise a single neuron neural network.\n",
    "    neural_network = NeuralNetwork()\n",
    "\n",
    "    print (\"Random starting synaptic weights: \")\n",
    "    print (neural_network.synaptic_weights)\n",
    "    # The training set. We have 4 examples, each consisting of 3 input values\n",
    "    # and 1 output value.\n",
    "    training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "    training_set_outputs = array([[0, 1, 1, 0]]).T #轉至？ 試驗OK\n",
    "\n",
    "    # Train the neural network using a training set.\n",
    "    # Do it 10,000 times and make small adjustments each time.\n",
    "    neural_network.train(training_set_inputs, training_set_outputs, 10000)\n",
    "\n",
    "    print (\"New synaptic weights after training: \")\n",
    "    print (neural_network.synaptic_weights)\n",
    "\n",
    "    # Test the neural network with a new situation.\n",
    "    print (\"Considering new situation [1, 0, 0] -> ?: \")\n",
    "    print (neural_network.think(array([1, 0, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = array([[0,1,1,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7039  | total loss: \u001b[1m\u001b[32m0.06181\u001b[0m\u001b[0m | time: 132.359s\n",
      "| Adam | epoch: 010 | loss: 0.06181 - acc: 0.9874 -- iter: 22496/22500\n",
      "Training Step: 7040  | total loss: \u001b[1m\u001b[32m0.05772\u001b[0m\u001b[0m | time: 137.216s\n",
      "| Adam | epoch: 010 | loss: 0.05772 - acc: 0.9887 | val_loss: 0.72783 - val_acc: 0.8080 -- iter: 22500/22500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical, pad_sequences\n",
    "from tflearn.datasets import imdb\n",
    "\n",
    "# IMDB Dataset loading\n",
    "train, test, _ = imdb.load_data(path='imdb.pkl', n_words=10000,\n",
    "                                valid_portion=0.1)\n",
    "trainX, trainY = train\n",
    "testX, testY = test\n",
    "\n",
    "# Data preprocessing\n",
    "# Sequence padding\n",
    "trainX = pad_sequences(trainX, maxlen=100, value=0.)\n",
    "testX = pad_sequences(testX, maxlen=100, value=0.)\n",
    "# Converting labels to binary vectors\n",
    "trainY = to_categorical(trainY, nb_classes=2)\n",
    "testY = to_categorical(testY, nb_classes=2)\n",
    "\n",
    "# Network building\n",
    "net = tflearn.input_data([None, 100])\n",
    "net = tflearn.embedding(net, input_dim=10000, output_dim=128)\n",
    "net = tflearn.lstm(net, 128, dropout=0.8)\n",
    "net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', learning_rate=0.001,\n",
    "                         loss='categorical_crossentropy')\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(trainX, trainY, validation_set=(testX, testY), show_metric=True,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class4 簡單訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.502579215892\n",
      "Error:0.0118721020065\n",
      "Error:0.0081187752366\n",
      "Error:0.00653891594771\n",
      "Error:0.00561784394993\n",
      "Error:0.00499748709862\n"
     ]
    }
   ],
   "source": [
    "# Step 1 Collect Data\n",
    "x = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "            [1],\n",
    "            [1],\n",
    "            [0]])\n",
    "\n",
    "#Step 2 build model\n",
    "\n",
    "num_epochs = 60000\n",
    "\n",
    "#initialize weights\n",
    "syn0 = 2*np.random.random((3,4)) - 1\n",
    "syn1 = 2*np.random.random((4,1)) - 1\n",
    "\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#Step 3 Train Model\n",
    "\n",
    "for j in range(num_epochs):\n",
    "    #feed forward through layers 0,1, and 2\n",
    "    k0 = x\n",
    "    k1 = nonlin(np.dot(k0, syn0))#變成1*4的矩陣,[1,2,3,4]\n",
    "    k2 = nonlin(np.dot(k1, syn1))#變成4*1\n",
    "    \n",
    "    #how much did we miss the target value?\n",
    "    k2_error = y - k2\n",
    "    \n",
    "    if (j% 10000) == 0:\n",
    "        print (\"Error:\" + str(np.mean(np.abs(k2_error))))\n",
    "    \n",
    "    #in what direction is the target value?\n",
    "    k2_delta = k2_error*nonlin(k2, deriv=True)\n",
    "    \n",
    "    #how much did each k1 value contribute to k2 error\n",
    "    k1_error = k2_delta.dot(syn1.T)\n",
    "    \n",
    "    k1_delta= k1_error * nonlin(k1,deriv=True)\n",
    "    \n",
    "    syn1 += k1.T.dot(k2_delta)\n",
    "    syn0 += k0.T.dot(k1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.20838376,   0.07757927,   3.13425584,  -0.44752369],\n",
       "       [  2.73946091,   0.96050992,  -4.09881663,   0.2396529 ],\n",
       "       [  2.75633627,   0.54408496,  -4.11596433,   0.51557552],\n",
       "       [ -2.71258659,   1.42701561, -11.3490368 ,   1.20275211]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x, syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00437122],\n",
       "       [ 0.99563975],\n",
       "       [ 0.99563644],\n",
       "       [ 0.00507964]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99727712e-01,   5.19384657e-01,   9.58283770e-01,\n",
       "          3.89949710e-01],\n",
       "       [  9.39315235e-01,   7.23223400e-01,   1.63215198e-02,\n",
       "          5.59628245e-01],\n",
       "       [  9.40270074e-01,   6.32762051e-01,   1.60484815e-02,\n",
       "          6.26112484e-01],\n",
       "       [  6.22348608e-02,   8.06435701e-01,   1.17807646e-05,\n",
       "          7.69014007e-01]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mPython Version: 3.5.4\u001b[0m\n",
      "\u001b[33mTensorFlow Ver: 1.4.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "from termcolor import colored\n",
    "print(colored('Python Version: %s' % sys.version.split()[0], 'blue'))\n",
    "print(colored('TensorFlow Ver: %s' % tf.__version__, 'yellow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class5 資料處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"database.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6.0\n",
       "1    5.8\n",
       "2    6.2\n",
       "3    5.8\n",
       "4    5.8\n",
       "5    6.7\n",
       "6    5.9\n",
       "7    6.0\n",
       "8    6.0\n",
       "9    5.8\n",
       "Name: Magnitude, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Magnitude.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23412 entries, 0 to 23411\n",
      "Data columns (total 21 columns):\n",
      "Date                          23412 non-null object\n",
      "Time                          23412 non-null object\n",
      "Latitude                      23412 non-null float64\n",
      "Longitude                     23412 non-null float64\n",
      "Type                          23412 non-null object\n",
      "Depth                         23412 non-null float64\n",
      "Depth Error                   4461 non-null float64\n",
      "Depth Seismic Stations        7097 non-null float64\n",
      "Magnitude                     23412 non-null float64\n",
      "Magnitude Type                23409 non-null object\n",
      "Magnitude Error               327 non-null float64\n",
      "Magnitude Seismic Stations    2564 non-null float64\n",
      "Azimuthal Gap                 7299 non-null float64\n",
      "Horizontal Distance           1604 non-null float64\n",
      "Horizontal Error              1156 non-null float64\n",
      "Root Mean Square              17352 non-null float64\n",
      "ID                            23412 non-null object\n",
      "Source                        23412 non-null object\n",
      "Location Source               23412 non-null object\n",
      "Magnitude Source              23412 non-null object\n",
      "Status                        23412 non-null object\n",
      "dtypes: float64(12), object(9)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Time', 'Latitude', 'Longitude', 'Type', 'Depth', 'Depth Error',\n",
       "       'Depth Seismic Stations', 'Magnitude', 'Magnitude Type',\n",
       "       'Magnitude Error', 'Magnitude Seismic Stations', 'Azimuthal Gap',\n",
       "       'Horizontal Distance', 'Horizontal Error', 'Root Mean Square', 'ID',\n",
       "       'Source', 'Location Source', 'Magnitude Source', 'Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>Root Mean Square</th>\n",
       "      <th>Magnitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>95.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>565.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>227.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>55.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>482.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>31.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>25.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23382</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23383</th>\n",
       "      <td>22.37</td>\n",
       "      <td>1.0100</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23384</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23385</th>\n",
       "      <td>71.26</td>\n",
       "      <td>1.2600</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23386</th>\n",
       "      <td>94.54</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23387</th>\n",
       "      <td>83.36</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23388</th>\n",
       "      <td>26.50</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23389</th>\n",
       "      <td>37.39</td>\n",
       "      <td>0.7100</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23390</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23391</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23392</th>\n",
       "      <td>12.43</td>\n",
       "      <td>1.0200</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23393</th>\n",
       "      <td>57.52</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23394</th>\n",
       "      <td>622.54</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23395</th>\n",
       "      <td>16.65</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23396</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.8300</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23397</th>\n",
       "      <td>10.00</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23398</th>\n",
       "      <td>10.38</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23399</th>\n",
       "      <td>152.00</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23400</th>\n",
       "      <td>12.05</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23401</th>\n",
       "      <td>35.00</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23402</th>\n",
       "      <td>30.00</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23403</th>\n",
       "      <td>38.00</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23404</th>\n",
       "      <td>14.93</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23405</th>\n",
       "      <td>97.00</td>\n",
       "      <td>0.7800</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23406</th>\n",
       "      <td>10.80</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23407</th>\n",
       "      <td>12.30</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23408</th>\n",
       "      <td>8.80</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23409</th>\n",
       "      <td>10.00</td>\n",
       "      <td>1.5200</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23410</th>\n",
       "      <td>79.00</td>\n",
       "      <td>1.4300</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23411</th>\n",
       "      <td>11.94</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Depth  Root Mean Square  Magnitude\n",
       "0      131.60               NaN        6.0\n",
       "1       80.00               NaN        5.8\n",
       "2       20.00               NaN        6.2\n",
       "3       15.00               NaN        5.8\n",
       "4       15.00               NaN        5.8\n",
       "5       35.00               NaN        6.7\n",
       "6       20.00               NaN        5.9\n",
       "7       35.00               NaN        6.0\n",
       "8       95.00               NaN        6.0\n",
       "9      565.00               NaN        5.8\n",
       "10     227.90               NaN        5.9\n",
       "11      20.00               NaN        8.2\n",
       "12      55.00               NaN        5.5\n",
       "13     482.90               NaN        5.6\n",
       "14      15.00               NaN        6.0\n",
       "15      10.00               NaN        6.1\n",
       "16      30.30               NaN        8.7\n",
       "17      30.00               NaN        6.0\n",
       "18      25.00               NaN        5.7\n",
       "19      25.00               NaN        5.8\n",
       "20      25.00               NaN        5.9\n",
       "21      20.00               NaN        5.9\n",
       "22      10.00               NaN        5.7\n",
       "23      24.00               NaN        5.7\n",
       "24      31.80               NaN        5.7\n",
       "25      20.00               NaN        5.6\n",
       "26      30.00               NaN        7.3\n",
       "27      30.00               NaN        6.5\n",
       "28      20.00               NaN        5.6\n",
       "29      25.00               NaN        6.4\n",
       "...       ...               ...        ...\n",
       "23382   10.00            0.9000        5.5\n",
       "23383   22.37            1.0100        6.0\n",
       "23384   10.00            0.7400        5.5\n",
       "23385   71.26            1.2600        5.5\n",
       "23386   94.54            0.9700        7.9\n",
       "23387   83.36            0.7100        5.6\n",
       "23388   26.50            0.8100        6.3\n",
       "23389   37.39            0.7100        5.9\n",
       "23390   10.00            0.8000        5.5\n",
       "23391   10.00            0.8700        5.9\n",
       "23392   12.43            1.0200        6.2\n",
       "23393   57.52            0.7900        5.5\n",
       "23394  622.54            0.6500        6.4\n",
       "23395   16.65            0.8900        6.4\n",
       "23396   10.00            0.8300        5.6\n",
       "23397   10.00            0.8800        6.0\n",
       "23398   10.38            0.7000        5.5\n",
       "23399  152.00            1.2000        6.7\n",
       "23400   12.05            0.7600        5.9\n",
       "23401   35.00            0.9100        6.0\n",
       "23402   30.00            0.8500        5.8\n",
       "23403   38.00            0.8000        7.6\n",
       "23404   14.93            0.5200        5.6\n",
       "23405   97.00            0.7800        5.6\n",
       "23406   10.80            0.1988        5.6\n",
       "23407   12.30            0.1898        5.6\n",
       "23408    8.80            0.2187        5.5\n",
       "23409   10.00            1.5200        5.9\n",
       "23410   79.00            1.4300        6.3\n",
       "23411   11.94            0.9100        5.5\n",
       "\n",
       "[23412 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Depth\",\"Root Mean Square\",\"Magnitude\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class6  Make an Image Classifier\n",
    "\n",
    "https://github.com/llSourcell/how_to_make_an_image_classifier/blob/master/demo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /Users/benwang/anaconda2/lib/python2.7/site-packages\n",
      "Requirement already satisfied: olefile in /Users/benwang/anaconda2/lib/python2.7/site-packages (from pillow)\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "ImportError: No module named keras\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow\n",
    "!KERAS_BACKEND=tensorflow python -c \"from keras import backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benwang/anaconda2/envs/python3.5/lib/python3.5/site-packages/ipykernel/__main__.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(150, 150,...)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/benwang/anaconda2/envs/python3.5/lib/python3.5/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "/Users/benwang/anaconda2/envs/python3.5/lib/python3.5/site-packages/ipykernel/__main__.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3))`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benwang/anaconda2/envs/python3.5/lib/python3.5/site-packages/ipykernel/__main__.py:9: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/Users/benwang/anaconda2/envs/python3.5/lib/python3.5/site-packages/ipykernel/__main__.py:9: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., steps_per_epoch=12, validation_steps=50, epochs=30, validation_data=<keras.pre...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12/12 [==============================] - 34s 3s/step - loss: 0.5359 - acc: 0.7240 - val_loss: 0.5060 - val_acc: 0.7469\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 33s 3s/step - loss: 0.5221 - acc: 0.7396 - val_loss: 0.5600 - val_acc: 0.7419\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 33s 3s/step - loss: 0.5114 - acc: 0.7292 - val_loss: 0.4532 - val_acc: 0.7987\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 33s 3s/step - loss: 0.5126 - acc: 0.7656 - val_loss: 0.5083 - val_acc: 0.7532\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 34s 3s/step - loss: 0.5620 - acc: 0.7396 - val_loss: 0.5044 - val_acc: 0.7619\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 33s 3s/step - loss: 0.5042 - acc: 0.7917 - val_loss: 0.5810 - val_acc: 0.7144\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 32s 3s/step - loss: 0.5822 - acc: 0.6771 - val_loss: 0.5225 - val_acc: 0.7069\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 33s 3s/step - loss: 0.5271 - acc: 0.7240 - val_loss: 0.5753 - val_acc: 0.7225\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 34s 3s/step - loss: 0.4323 - acc: 0.7865 - val_loss: 0.4818 - val_acc: 0.7750\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 33s 3s/step - loss: 0.5400 - acc: 0.7604 - val_loss: 0.4878 - val_acc: 0.7805\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 34s 3s/step - loss: 0.4972 - acc: 0.7448 - val_loss: 0.4911 - val_acc: 0.7581\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 33s 3s/step - loss: 0.5238 - acc: 0.7240 - val_loss: 0.5473 - val_acc: 0.7225\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 36s 3s/step - loss: 0.5033 - acc: 0.7500 - val_loss: 0.4912 - val_acc: 0.7582\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 34s 3s/step - loss: 0.5040 - acc: 0.7083 - val_loss: 0.5716 - val_acc: 0.6919\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 32s 3s/step - loss: 0.6112 - acc: 0.7083 - val_loss: 0.4843 - val_acc: 0.7762\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 32s 3s/step - loss: 0.5815 - acc: 0.7083 - val_loss: 0.5211 - val_acc: 0.7430\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 33s 3s/step - loss: 0.5399 - acc: 0.7396 - val_loss: 0.5032 - val_acc: 0.7569\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 33s 3s/step - loss: 0.5616 - acc: 0.6823 - val_loss: 0.5115 - val_acc: 0.7500\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 34s 3s/step - loss: 0.5122 - acc: 0.7552 - val_loss: 0.5143 - val_acc: 0.7525\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 33s 3s/step - loss: 0.4297 - acc: 0.7760 - val_loss: 0.5478 - val_acc: 0.7131\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 33s 3s/step - loss: 0.4664 - acc: 0.7917 - val_loss: 0.5315 - val_acc: 0.7412\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 34s 3s/step - loss: 0.5836 - acc: 0.7031 - val_loss: 0.5063 - val_acc: 0.7544\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 34s 3s/step - loss: 0.4545 - acc: 0.7448 - val_loss: 0.5560 - val_acc: 0.7406\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 32s 3s/step - loss: 0.5665 - acc: 0.7500 - val_loss: 0.5077 - val_acc: 0.7488\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 32s 3s/step - loss: 0.4804 - acc: 0.7760 - val_loss: 0.4762 - val_acc: 0.7669\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 32s 3s/step - loss: 0.5481 - acc: 0.7604 - val_loss: 0.5170 - val_acc: 0.7437\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 32s 3s/step - loss: 0.5502 - acc: 0.7031 - val_loss: 0.5092 - val_acc: 0.7669\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 32s 3s/step - loss: 0.4911 - acc: 0.7292 - val_loss: 0.4975 - val_acc: 0.7662\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 32s 3s/step - loss: 0.5297 - acc: 0.7812 - val_loss: 0.4918 - val_acc: 0.7608\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 32s 3s/step - loss: 0.4891 - acc: 0.7656 - val_loss: 0.5485 - val_acc: 0.7538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12f09f588>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = 30\n",
    "nb_train_samples = 200\n",
    "nb_validation_samples = 50\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        nb_epoch=nb_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'models/basic_cnn_20_epochs.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 602)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-1e70786389d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/basic_cnn_20_epochs.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/python3.5/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python3.5/lib/python3.5/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python3.5/lib/python3.5/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'models/basic_cnn_20_epochs.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 602)"
     ]
    }
   ],
   "source": [
    "model.save_weights('models/basic_cnn_20_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class7 Predict Stock Prices\n",
    "https://github.com/llSourcell/How-to-Predict-Stock-Prices-Easily-Demo/blob/master/stockdemo.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import lstm, time #helper libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 Load Data\n",
    "X_train, y_train, X_test, y_test = lstm.load_data('sp500.csv', 50, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 Build Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "    input_dim=1,\n",
    "    output_dim=50,\n",
    "    return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "    100,\n",
    "    return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(\n",
    "    output_dim=1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "start = time.time()\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "print 'compilation time : ', time.time() - start\n",
    "\n",
    "#Step 3 Train the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    nb_epoch=1,\n",
    "    validation_split=0.05)\n",
    "\n",
    "#Step 4 - Plot the predictions!\n",
    "predictions = lstm.predict_sequences_multiple(model, X_test, 50, 50)\n",
    "lstm.plot_results_multiple(predictions, y_test, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3.5]",
   "language": "python",
   "name": "conda-env-python3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
